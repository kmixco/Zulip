#!/usr/bin/env python3

# check for the venv
from lib import sanity_check

sanity_check.check_venv(__file__)

import argparse
import json
import logging
import os
import re
import subprocess
import sys

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from typing import Any, Dict, Iterable, List

from zulint import lister

from lib.html_branches import build_id_dict
from lib.template_parser import is_django_block_tag, tokenize, validate
from scripts.lib.zulip_tools import ENDC, FAIL, WARNING
from tools.lib.capitalization import IGNORED_PHRASES, check_capitalization

DJANGO_PO_REGEX = re.compile('msgid "(.*?)"')

EXCLUDED_FILES = [
    ## Test data Files for testing modules in tests
    "tools/tests/test_template_data",
    # Our parser doesn't handle the way its conditionals are layered
    'templates/zerver/emails/missed_message.source.html',
    # Previously unchecked and our parser doesn't like its indentation
    'static/assets/icons/template.hbs',
]

def check_files(modified_only: bool, no_generate: bool, targets: List[str]) -> None:
    by_lang = lister.list_files(
        targets=targets,
        modified_only=args.modified,
        ftypes=['hbs', 'html'],
        group_by_ftype=True, exclude=EXCLUDED_FILES,
    )

    check_handlebar(by_lang['hbs'])
    check_html(by_lang['html'], no_generate)
    check_python(by_lang['py'])

def check_html(templates: Iterable[str], no_generate: bool) -> None:
    # Our files with .html extensions are usually for Django, but we also
    # have a few static .html files.
    logging.basicConfig(format='%(levelname)s:%(message)s')
    templates = sorted(fn for fn in templates)
    # Use of lodash templates <%= %>.
    if 'templates/zerver/team.html' in templates:
        templates.remove('templates/zerver/team.html')

    def check_for_duplicate_ids(templates: List[str]) -> Dict[str, List[str]]:
        template_id_dict = build_id_dict(templates)
        # TODO: Clean up these cases of duplicate ids in the code
        IGNORE_IDS = [
            'api-example-tabs',
            'errors',
            'error-message-box',
            'email',
            'messages',
            'registration',
            'pw_strength',
            'id_password',
            'top_navbar',
            'id_email',
            'id_terms',
            'send_confirm',
            'register',
            'footer',
            'charged_amount',
            'change-plan-status',
            # Temporary while we have searchbox forked
            'search_exit',
            'search_query',
            'message_view_header',
            'search_arrows',
            'searchbox_form',
            'searchbox',
        ]
        bad_ids_dict = {ids: fns for ids, fns in template_id_dict.items()
                        if (ids not in IGNORED_IDS) and len(fns) > 1}

        if no_generate:
            ignorable_ids_dict = {ids: fns for ids, fns in template_id_dict.items()
                                  if ids in IGNORED_IDS and len(fns) > 1}

            for ids, fns in ignorable_ids_dict.items():
                logging.warning("Duplicate ID(s) detected :Id '" + ids +
                                "' present at following files:")
                for fn in fns:
                    print(fn)

        for ids, fns in bad_ids_dict.items():
            logging.error("Duplicate ID(s) detected :Id '" + ids +
                          "' present at following files:")
            for fn in fns:
                print(fn)
        return bad_ids_dict

    bad_ids_list: List[str] = []
    archive_templates = [fn for fn in templates if 'templates/zerver/archive' in fn]
    templates = [fn for fn in templates if 'templates/zerver/archive' not in fn]

    bad_ids_list += list(check_for_duplicate_ids(archive_templates).keys())
    bad_ids_list += list(check_for_duplicate_ids(templates).keys())

    if bad_ids_list:
        print('Exiting--please clean up all duplicates before running this again.')
        sys.exit(1)

    for fn in templates:
        # Many of our Django templates have strange indentation.  The
        # indentation errors are often harmless, even stylistically
        # harmless, but they tend to be in files that might be old
        # and might eventually require more scrutiny for things like
        # localization.  See GitHub #1236.
        bad_files = [
            # These use various whitespace-dependent formatting that
            # prevent cleaning them.
            'templates/corporate/zephyr-mirror.html',
            # Can't clean this because of `preserve_spaces`
            'templates/zerver/app/markdown_help.html',
        ]
        validate(fn=fn, check_indent=(fn not in bad_files))

    # Ignore these files since these have not been cleaned yet :/
    IGNORE_FILES = [
        # zephyr-mirror.html has some whitespace-dependent formatting
        # for code blocks that prevent cleaning it.  Might make sense
        # to convert it to a /help/ Markdown article.
        'templates/corporate/zephyr-mirror.html',
        # Can't clean this because of `preserve_spaces`
        'templates/zerver/app/markdown_help.html',
    ]
    # TODO: Clean these files
    for fn in templates:
        if fn not in IGNORE_FILES:
            if not validate_html(fn):
                sys.exit(1)

def check_handlebar(templates: Iterable[str]) -> None:
    # Check all our handlebars templates.
    templates = [fn for fn in templates if fn.endswith('.hbs')]

    IGNORE_FILES = [
        # TODO: Add some exclude mechanism for the line-wrapping issue here.
        'static/templates/recipient_row.hbs',
    ]

    for fn in templates:
        if fn in IGNORE_FILES:
            continue
        validate(fn=fn, check_indent=True)

    for fn in templates:
        if fn in IGNORE_FILES:
            continue
        if not validate_html(fn):
            sys.exit(1)

def check_python(templates: Iterable[str]) -> None:
    # Check all our python files.
    templates = [fn for fn in templates if fn.endswith('.py')]

    IGNORE_FILES = [
        # TODO: Add some exclude mechanism for the line-wrapping issue here.
        'zilencer/views.py'
    ]

    for fn in templates:
        if fn in IGNORE_FILES:
            continue
        validate(fn=fn, check_indent=True)

    for fn in templates:
        if fn in IGNORE_FILES:
            continue
        if not validate_html(fn):
            sys.exit(1)


def pretty_html(html: str, num_spaces: int = 4) -> str:
    # We use 1-based indexing for both rows and columns.
    tokens = tokenize(html)
    lines = html.split('\n')

    # We will keep a stack of "start" tags so that we know
    # when HTML ranges end.  Note that some start tags won't
    # be blocks from an indentation standpoint.
    stack: List[Dict[str, Any]] = []

    # Seed our stack with a pseudo entry to make depth calculations
    # easier.
    info: Dict[str, Any] = dict(
        block=False,
        depth=-1,
        line=-1,
        token_kind='html_start',
        tag='html',
        extra_indent=0,
        ignore_lines=[],
    )
    stack.append(info)

    # Our main job is to figure out offsets that we use to nudge lines
    # over by.
    offsets: Dict[int, int] = {}

    # Loop through our start/end tokens, and calculate offsets.  As
    # we proceed, we will push/pop info dictionaries on/off a stack.
    for token in tokens:

        if token.kind in ('html_start', 'handlebars_start', 'handlebars_singleton',
                          'html_singleton', 'django_start',
                          'jinja2_whitespace_stripped_type2_start',
                          'jinja2_whitespace_stripped_start',) and stack[-1]['tag'] != 'pre':
            # An HTML start tag should only cause a new indent if we
            # are on a new line.
            if (token.tag not in ('extends', 'include', 'else', 'elif') and
                    (is_django_block_tag(token.tag) or
                        token.kind != 'django_start')):
                is_block = token.line > stack[-1]['line']

                if is_block:
                    if (((token.kind == 'handlebars_start' and
                            stack[-1]['token_kind'] == 'handlebars_start') or
                            (token.kind in {'django_start',
                                            'jinja2_whitespace_stripped_type2_start',
                                            'jinja2_whitespace_stripped_start'} and
                             stack[-1]['token_kind'] in {'django_start',
                                                         'jinja2_whitespace_stripped_type2_start',
                                                         'jinja2_whitespace_stripped_start'})) and
                            not stack[-1]['indenting']):
                        info = stack.pop()
                        info['depth'] = info['depth'] + 1
                        info['indenting'] = True
                        info['adjust_offset_until'] = token.line
                        stack.append(info)
                    new_depth = stack[-1]['depth'] + 1
                    extra_indent = stack[-1]['extra_indent']
                    line = lines[token.line - 1]
                    adjustment = len(line)-len(line.lstrip()) + 1
                    offset = (1 + extra_indent + new_depth * num_spaces) - adjustment
                    info = dict(
                        block=True,
                        depth=new_depth,
                        actual_depth=new_depth,
                        line=token.line,
                        tag=token.tag,
                        token_kind=token.kind,
                        line_span=token.line_span,
                        offset=offset,
                        extra_indent=token.col - adjustment + extra_indent,
                        extra_indent_prev=extra_indent,
                        adjustment=adjustment,
                        indenting=True,
                        adjust_offset_until=token.line,
                        ignore_lines=[],
                    )
                    if token.kind in ('handlebars_start', 'django_start'):
                        info.update(dict(depth=new_depth - 1, indenting=False))
                else:
                    info = dict(
                        block=False,
                        depth=stack[-1]['depth'],
                        actual_depth=stack[-1]['depth'],
                        line=token.line,
                        tag=token.tag,
                        token_kind=token.kind,
                        extra_indent=stack[-1]['extra_indent'],
                        ignore_lines=[],
                    )
                stack.append(info)
        elif (token.kind in ('html_end', 'handlebars_end', 'html_singleton_end',
                             'django_end', 'handlebars_singleton_end',
                             'jinja2_whitespace_stripped_end',) and
              (stack[-1]['tag'] != 'pre' or token.tag == 'pre')):
            info = stack.pop()
            if info['block']:
                # We are at the end of an indentation block.  We
                # assume the whole block was formatted ok before, just
                # possibly at an indentation that we don't like, so we
                # nudge over all lines in the block by the same offset.
                start_line = info['line']
                end_line = token.line
                if token.tag == 'pre':
                    offsets[start_line] = 0
                    offsets[end_line] = 0
                    stack[-1]['ignore_lines'].append(start_line)
                    stack[-1]['ignore_lines'].append(end_line)
                else:
                    offsets[start_line] = info['offset']
                    line = lines[token.line - 1]
                    adjustment = len(line)-len(line.lstrip()) + 1
                    if adjustment == token.col and token.kind != 'html_singleton_end':
                        offsets[end_line] = (info['offset'] +
                                             info['adjustment'] -
                                             adjustment +
                                             info['extra_indent'] -
                                             info['extra_indent_prev'])
                    elif (start_line + info['line_span'] - 1 == end_line and
                            info['line_span'] > 1):
                        offsets[end_line] = (1 + info['extra_indent'] +
                                             (info['depth'] + 1) * num_spaces) - adjustment
                        # We would like singleton tags and tags which spread over
                        # multiple lines to have 2 space indentation.
                        offsets[end_line] -= 2
                    elif token.line != info['line']:
                        offsets[end_line] = info['offset']
                if token.tag != 'pre' and token.tag != 'script':
                    for line_num in range(start_line + 1, end_line):
                        # Be careful not to override offsets that happened
                        # deeper in the HTML within our block.
                        if line_num not in offsets:
                            line = lines[line_num - 1]
                            new_depth = info['depth'] + 1
                            if (line.lstrip().startswith('{{else}}') or
                                    line.lstrip().startswith('{% else %}') or
                                    line.lstrip().startswith('{% elif')):
                                new_depth = info['actual_depth']
                            extra_indent = info['extra_indent']
                            adjustment = len(line)-len(line.lstrip()) + 1
                            offset = (1 + extra_indent + new_depth * num_spaces) - adjustment
                            if line_num <= start_line + info['line_span'] - 1:
                                # We would like singleton tags and tags which spread over
                                # multiple lines to have 2 space indentation.
                                offset -= 2
                            offsets[line_num] = offset
                        elif (token.kind in ('handlebars_end', 'django_end') and
                                info['indenting'] and
                                line_num < info['adjust_offset_until'] and
                                line_num not in info['ignore_lines']):
                            offsets[line_num] += num_spaces
                elif token.tag != 'pre':
                    for line_num in range(start_line + 1, end_line):
                        if line_num not in offsets:
                            offsets[line_num] = info['offset']
                else:
                    for line_num in range(start_line + 1, end_line):
                        if line_num not in offsets:
                            offsets[line_num] = 0
                            stack[-1]['ignore_lines'].append(line_num)

    # Now that we have all of our offsets calculated, we can just
    # join all our lines together, fixing up offsets as needed.
    formatted_lines = []
    for i, line in enumerate(html.split('\n')):
        row = i + 1
        offset = offsets.get(row, 0)
        pretty_line = line
        if line.strip() == '':
            pretty_line = ''
        else:
            if offset > 0:
                pretty_line = (' ' * offset) + pretty_line
            elif offset < 0:
                pretty_line = pretty_line[-1 * offset:]
                assert line.strip() == pretty_line.strip()
        formatted_lines.append(pretty_line)

    return '\n'.join(formatted_lines)




def validate_html(fn: str) -> int:
    print("function" + fn)
    with open(fn) as f:
        html1 = f.read()
    phtml1 = pretty_html(html1)
    if html1.split('\n') != phtml1.split('\n'):
        print("hello" + fn)

        if not args.no_generate:
            subprocess.call(['./manage.py', 'makemessages', '--locale', 'en'],
                            stderr=subprocess.STDOUT)

        with open('locale/en/translations.json') as f:
            data = json.load(f)
            frontend = check_capitalization(list(data.keys()))
            frontend_errors, frontend_ignored, banned_errors_front = frontend

        with open('locale/en/LC_MESSAGES/django.po') as f:
            rows = [r for r in DJANGO_PO_REGEX.findall(f.read()) if r]
            backend = check_capitalization(rows)
            backend_errors, backend_ignored, banned_errors_back = backend

        if frontend_errors:
            print(WARNING + 'Strings not properly capitalized in frontend file:'
                  f'{fn}'  + ENDC)
            subprocess.run(['diff', fn, '-'], input=phtml1, universal_newlines=True)
            print('\n'.join(frontend_errors))

        if backend_errors:
            print(WARNING + 'Strings not properly capitalized in backend file:'
                  f'{fn}' + ENDC)
            subprocess.run(['diff', fn, '-'], input=phtml1, universal_newlines=True)
            print('\n'.join(backend_errors))

        if banned_errors_front:
            print(WARNING + "Found banned words in frontend strings" + ENDC)
            print('\n'.join(banned_errors_front))

        if banned_errors_back:
            print(WARNING + "Found banned words in backend strings" + ENDC)
            print('\n'.join(banned_errors_back))

        if args.show_ignored:
            print(WARNING + "Strings which were ignored: " + ENDC)
            print('\n'.join(frontend_ignored + backend_ignored))

        if frontend_errors or backend_errors or banned_errors_back or banned_errors_front:
            # Point the user to the documentation on what the policy is.
            docs_url = "https://zulip.readthedocs.io/en/latest/translating/translating.html#capitalization"
            print(WARNING + "See " + docs_url + ENDC)
            print(FAIL + "Failed!" + ENDC)
            sys.exit(1)
        else:
            sys.exit(0)

    return 0

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('-m', '--modified',
                        action='store_true',
                        help='only check modified files')
    parser.add_argument('--show-ignored',
                        action='store_true',
                        help='Show strings that passed the check because they '
                             'contained ignored phrases.')
    parser.add_argument('--no-generate',
                        action='store_true',
                        help="Don't run makemessages command.")
    parser.add_argument('targets', nargs=argparse.REMAINDER)
    args = parser.parse_args()
    print(args.no_generate)
    check_files(args.modified, args.no_generate, args.targets)
